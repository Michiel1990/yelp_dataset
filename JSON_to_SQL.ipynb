{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a4aad642",
   "metadata": {},
   "source": [
    "#### import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34e54d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import itertools\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93c3ea8",
   "metadata": {},
   "source": [
    "#### define variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3767a746",
   "metadata": {},
   "outputs": [],
   "source": [
    "#JSON file locations\n",
    "business_json= 'C:/Users/Gebruiker/Jupyter/yelp_dataset/JSON/yelp_academic_dataset_business.json'\n",
    "checkin_json=  'C:/Users/Gebruiker/Jupyter/yelp_dataset/JSON/yelp_academic_dataset_checkin.json'\n",
    "review_json=   'C:/Users/Gebruiker/Jupyter/yelp_dataset/JSON/yelp_academic_dataset_review.json'\n",
    "tip_json=      'C:/Users/Gebruiker/Jupyter/yelp_dataset/JSON/yelp_academic_dataset_tip.json'\n",
    "user_json=     'C:/Users/Gebruiker/Jupyter/yelp_dataset/JSON/yelp_academic_dataset_user.json'\n",
    "\n",
    "#SQLite3 connection\n",
    "conn = sqlite3.connect('SQLITE3/yelp_database.sqlite3')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a81525",
   "metadata": {},
   "source": [
    "### I) BUSINESS DATA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "098db450",
   "metadata": {},
   "source": [
    "#### 0) load & normalize JSON file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df00a8a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160585 entries, 0 to 160584\n",
      "Data columns (total 58 columns):\n",
      " #   Column                                 Non-Null Count   Dtype  \n",
      "---  ------                                 --------------   -----  \n",
      " 0   business_id                            160585 non-null  object \n",
      " 1   name                                   160585 non-null  object \n",
      " 2   address                                160585 non-null  object \n",
      " 3   city                                   160585 non-null  object \n",
      " 4   state                                  160585 non-null  object \n",
      " 5   postal_code                            160585 non-null  object \n",
      " 6   latitude                               160585 non-null  float64\n",
      " 7   longitude                              160585 non-null  float64\n",
      " 8   stars                                  160585 non-null  float64\n",
      " 9   review_count                           160585 non-null  int64  \n",
      " 10  is_open                                160585 non-null  int64  \n",
      " 11  categories                             160470 non-null  object \n",
      " 12  attributes.RestaurantsTableService     19400 non-null   object \n",
      " 13  attributes.WiFi                        59017 non-null   object \n",
      " 14  attributes.BikeParking                 76480 non-null   object \n",
      " 15  attributes.BusinessParking             98163 non-null   object \n",
      " 16  attributes.BusinessAcceptsCreditCards  120177 non-null  object \n",
      " 17  attributes.RestaurantsReservations     45607 non-null   object \n",
      " 18  attributes.WheelchairAccessible        29370 non-null   object \n",
      " 19  attributes.Caters                      40140 non-null   object \n",
      " 20  attributes.OutdoorSeating              50128 non-null   object \n",
      " 21  attributes.RestaurantsGoodForGroups    45381 non-null   object \n",
      " 22  attributes.HappyHour                   15237 non-null   object \n",
      " 23  attributes.BusinessAcceptsBitcoin      17593 non-null   object \n",
      " 24  attributes.RestaurantsPriceRange2      92442 non-null   object \n",
      " 25  attributes.Ambience                    43882 non-null   object \n",
      " 26  attributes.HasTV                       44495 non-null   object \n",
      " 27  attributes.Alcohol                     44443 non-null   object \n",
      " 28  attributes.GoodForMeal                 29276 non-null   object \n",
      " 29  attributes.DogsAllowed                 18308 non-null   object \n",
      " 30  attributes.RestaurantsTakeOut          58412 non-null   object \n",
      " 31  attributes.NoiseLevel                  39193 non-null   object \n",
      " 32  attributes.RestaurantsAttire           40723 non-null   object \n",
      " 33  attributes.RestaurantsDelivery         54485 non-null   object \n",
      " 34  hours.Monday                           121672 non-null  object \n",
      " 35  hours.Tuesday                          126944 non-null  object \n",
      " 36  hours.Wednesday                        129469 non-null  object \n",
      " 37  hours.Thursday                         130753 non-null  object \n",
      " 38  hours.Friday                           130177 non-null  object \n",
      " 39  hours.Saturday                         113021 non-null  object \n",
      " 40  hours.Sunday                           83780 non-null   object \n",
      " 41  attributes.GoodForKids                 56850 non-null   object \n",
      " 42  attributes.ByAppointmentOnly           49748 non-null   object \n",
      " 43  attributes.AcceptsInsurance            7168 non-null    object \n",
      " 44  attributes.HairSpecializesIn           1193 non-null    object \n",
      " 45  attributes.GoodForDancing              4758 non-null    object \n",
      " 46  attributes.BestNights                  5526 non-null    object \n",
      " 47  attributes.Music                       7198 non-null    object \n",
      " 48  attributes.BYOB                        3519 non-null    object \n",
      " 49  attributes.CoatCheck                   5188 non-null    object \n",
      " 50  attributes.Smoking                     4419 non-null    object \n",
      " 51  attributes.DriveThru                   6038 non-null    object \n",
      " 52  attributes.BYOBCorkage                 3667 non-null    object \n",
      " 53  attributes.Corkage                     3973 non-null    object \n",
      " 54  attributes.RestaurantsCounterService   40 non-null      object \n",
      " 55  attributes.AgesAllowed                 97 non-null      object \n",
      " 56  attributes.DietaryRestrictions         68 non-null      object \n",
      " 57  attributes.Open24Hours                 42 non-null      object \n",
      "dtypes: float64(3), int64(2), object(53)\n",
      "memory usage: 71.1+ MB\n"
     ]
    }
   ],
   "source": [
    "#open file as txt, read line per line, and place in a list\n",
    "business_lines = open(business_json, 'r', encoding='utf-8').readlines()\n",
    "\n",
    "#as python places a \"/n\" newline at the end of each line, we need to strip these to achieve valid JSON\n",
    "    #then create a list of JSON dict objects, line per line\n",
    "list_business_JSON_objects = []\n",
    "for line in business_lines:\n",
    "    list_business_JSON_objects.append(json.loads(line.strip()))\n",
    "\n",
    "#create a normalized DF out of the JSON object list\n",
    "business_df = pd.json_normalize(list_business_JSON_objects, max_level=1)\n",
    "\n",
    "#drop empty columns\n",
    "business_df = business_df.drop(['hours','attributes'], axis=1)\n",
    "\n",
    "#column list for later use\n",
    "complete_df_column_list = business_df.columns.tolist()\n",
    "\n",
    "business_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b928d63e",
   "metadata": {},
   "source": [
    "#### 1) Main businesses table / general (level 1) attributes table / hours table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b658508",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the original DF into 3 tables; \n",
    "#one \"main\":\n",
    "business_main_df = business_df[['business_id','name','address','city','state','postal_code','latitude','longitude','stars','review_count','is_open','categories']].copy()\n",
    "\n",
    "business_main_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c6c466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#) create and fill SQLite3 table (including PK index)\n",
    "c.execute('DROP TABLE IF EXISTS business_main')\n",
    "conn.commit()\n",
    "\n",
    "c.execute(\"\"\"CREATE TABLE business_main(\n",
    "                business_id text PRIMARY KEY\n",
    "                ,name text\n",
    "                ,address text\n",
    "                ,city text\n",
    "                ,state text\n",
    "                ,postal_code text\n",
    "                ,latitude real\n",
    "                ,longitude real\n",
    "                ,stars real\n",
    "                ,review_count integer\n",
    "                ,is_open integer\n",
    "                ,categories text)\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "business_main_df.to_sql('business_main', conn, if_exists='append', index = False)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccb48c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 160585 entries, 0 to 160584\n",
      "Data columns (total 35 columns):\n",
      " #   Column                      Non-Null Count   Dtype \n",
      "---  ------                      --------------   ----- \n",
      " 0   business_id                 160585 non-null  object\n",
      " 1   RestaurantsTableService     19400 non-null   object\n",
      " 2   WiFi                        59017 non-null   object\n",
      " 3   BikeParking                 76480 non-null   object\n",
      " 4   BusinessAcceptsCreditCards  120177 non-null  object\n",
      " 5   RestaurantsReservations     45607 non-null   object\n",
      " 6   WheelchairAccessible        29370 non-null   object\n",
      " 7   Caters                      40140 non-null   object\n",
      " 8   OutdoorSeating              50128 non-null   object\n",
      " 9   RestaurantsGoodForGroups    45381 non-null   object\n",
      " 10  HappyHour                   15237 non-null   object\n",
      " 11  BusinessAcceptsBitcoin      17593 non-null   object\n",
      " 12  RestaurantsPriceRange2      92442 non-null   object\n",
      " 13  HasTV                       44495 non-null   object\n",
      " 14  Alcohol                     44443 non-null   object\n",
      " 15  DogsAllowed                 18308 non-null   object\n",
      " 16  RestaurantsTakeOut          58412 non-null   object\n",
      " 17  NoiseLevel                  39193 non-null   object\n",
      " 18  RestaurantsAttire           40723 non-null   object\n",
      " 19  RestaurantsDelivery         54485 non-null   object\n",
      " 20  GoodForKids                 56850 non-null   object\n",
      " 21  ByAppointmentOnly           49748 non-null   object\n",
      " 22  AcceptsInsurance            7168 non-null    object\n",
      " 23  HairSpecializesIn           1193 non-null    object\n",
      " 24  GoodForDancing              4758 non-null    object\n",
      " 25  BYOB                        3519 non-null    object\n",
      " 26  CoatCheck                   5188 non-null    object\n",
      " 27  Smoking                     4419 non-null    object\n",
      " 28  DriveThru                   6038 non-null    object\n",
      " 29  BYOBCorkage                 3667 non-null    object\n",
      " 30  Corkage                     3973 non-null    object\n",
      " 31  RestaurantsCounterService   40 non-null      object\n",
      " 32  AgesAllowed                 97 non-null      object\n",
      " 33  DietaryRestrictions         68 non-null      object\n",
      " 34  Open24Hours                 42 non-null      object\n",
      "dtypes: object(35)\n",
      "memory usage: 42.9+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Gebruiker\\AppData\\Local\\Temp\\ipykernel_22072\\3096983629.py:12: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  general_attributes_df.columns = general_attributes_df.columns.str.replace('attributes.', '')\n"
     ]
    }
   ],
   "source": [
    "#one with general attributes:\n",
    "\n",
    "#fetch relevant columns\n",
    "attributes_column_list = [x for x in complete_df_column_list if x.startswith('attributes.')]\n",
    "attributes_column_list.insert(0,'business_id')\n",
    "general_attributes_df = business_df[attributes_column_list]\n",
    "\n",
    "#drop 5 columns with nested objects (will be extracted later)\n",
    "general_attributes_df = general_attributes_df.drop(['attributes.BusinessParking','attributes.Ambience','attributes.GoodForMeal','attributes.BestNights','attributes.Music'], axis=1)\n",
    "\n",
    "#remove \"attributes.\" from column names for use in SQL\n",
    "general_attributes_df.columns = general_attributes_df.columns.str.replace('attributes.', '')\n",
    "\n",
    "general_attributes_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "683c01c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#) create and fill SQLite3 table (including FK index)\n",
    "c.execute('DROP TABLE IF EXISTS attributes_general_staging')\n",
    "conn.commit()\n",
    "\n",
    "c.execute(\"\"\"CREATE TABLE attributes_general_staging (\n",
    "                    \"business_id\" TEXT\n",
    "                    ,\"RestaurantsTableService\" integer\n",
    "                    ,\"WiFi\" TEXT\n",
    "                    ,\"BikeParking\" integer\n",
    "                    ,\"BusinessAcceptsCreditCards\" integer\n",
    "                    ,\"RestaurantsReservations\" integer\n",
    "                    ,\"WheelchairAccessible\" integer\n",
    "                    ,\"Caters\" integer\n",
    "                    ,\"OutdoorSeating\" integer\n",
    "                    ,\"RestaurantsGoodForGroups\" integer\n",
    "                    ,\"HappyHour\" integer\n",
    "                    ,\"BusinessAcceptsBitcoin\" integer\n",
    "                    ,\"RestaurantsPriceRange2\" integer\n",
    "                    ,\"HasTV\" integer\n",
    "                    ,\"Alcohol\" TEXT\n",
    "                    ,\"DogsAllowed\" integer\n",
    "                    ,\"RestaurantsTakeOut\" integer\n",
    "                    ,\"NoiseLevel\" TEXT\n",
    "                    ,\"RestaurantsAttire\" TEXT\n",
    "                    ,\"RestaurantsDelivery\" integer\n",
    "                    ,\"GoodForKids\" integer\n",
    "                    ,\"ByAppointmentOnly\" integer\n",
    "                    ,\"AcceptsInsurance\" integer\n",
    "                    ,\"HairSpecializesIn\" TEXT\n",
    "                    ,\"GoodForDancing\" integer\n",
    "                    ,\"BYOB\" integer\n",
    "                    ,\"CoatCheck\" integer\n",
    "                    ,\"Smoking\" TEXT\n",
    "                    ,\"DriveThru\" integer\n",
    "                    ,\"BYOBCorkage\" TEXT\n",
    "                    ,\"Corkage\" integer\n",
    "                    ,\"RestaurantsCounterService\" integer\n",
    "                    ,\"AgesAllowed\" TEXT\n",
    "                    ,\"DietaryRestrictions\" TEXT\n",
    "                    ,\"Open24Hours\" integer\n",
    "                    ,CONSTRAINT fk_business_id  \n",
    "                    FOREIGN KEY (business_id)  \n",
    "                    REFERENCES business_main(business_id))\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "general_attributes_df.to_sql('attributes_general_staging', conn, if_exists='append', index = False)\n",
    "conn.commit()\n",
    "\n",
    "c.execute('CREATE INDEX IDX_attributes_general_staging on attributes_general_staging(business_id)')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1634127c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#and one with hours:\n",
    "\n",
    "#fetch relevant columns\n",
    "hours_column_list = [x for x in complete_df_column_list if x.startswith('hours.')]\n",
    "hours_column_list.insert(0,'business_id')\n",
    "hours_df = business_df[hours_column_list]\n",
    "\n",
    "#remove \"attributes.\" from column names for use in SQL\n",
    "hours_df.columns = hours_df.columns.str.replace('hours.', '')\n",
    "\n",
    "hours_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee66a730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#) create and fill SQLite3 table (including FK index)\n",
    "c.execute('DROP TABLE IF EXISTS business_hours')\n",
    "conn.commit()\n",
    "\n",
    "c.execute(\"\"\"CREATE TABLE business_hours(\n",
    "                business_id text\n",
    "                ,Monday text\n",
    "                ,Tuesday text\n",
    "                ,Wednesday text\n",
    "                ,Thursday text\n",
    "                ,Friday text\n",
    "                ,Saturday text\n",
    "                ,Sunday text\n",
    "                ,CONSTRAINT fk_business_id  \n",
    "                FOREIGN KEY (business_id)  \n",
    "                REFERENCES business_main(business_id))\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "c.execute('CREATE INDEX IDX_business_hours on business_hours(business_id)')\n",
    "conn.commit()\n",
    "\n",
    "hours_df.to_sql('business_hours', conn, if_exists='append', index = False)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e18ca3",
   "metadata": {},
   "source": [
    "#### level 2 normalization\n",
    "> manual action required (instead of raising max_level attribute in (1)) because the business dataset contains nested object columns with unvalid JSON strings; for following columns: attributes.BusinessParking / attributes.Ambience / attributes.GoodForMeal / attributes.BestNights / attributes.Music"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ec90e",
   "metadata": {},
   "source": [
    "#### 2) attributes.BusinessParking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f6464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A) the clean-up (including quotes, booleans and nan values)\n",
    "business_df['attributes.BusinessParking'] = business_df['attributes.BusinessParking'].replace(\"'\",'\"', regex=True)\n",
    "business_df['attributes.BusinessParking'] = business_df['attributes.BusinessParking'].replace('True','true', regex=True)\n",
    "business_df['attributes.BusinessParking'] = business_df['attributes.BusinessParking'].replace('False','false', regex=True)\n",
    "business_df['attributes.BusinessParking'] = business_df['attributes.BusinessParking'].replace('None','null', regex=True)\n",
    "\n",
    "#B) the normalization where we only apply JSON loads for x==x (NaN receives empty dict)\n",
    "BusinessParking_df = pd.json_normalize(business_df['attributes.BusinessParking'].apply(lambda x: json.loads(x) if(x == x) else {}))\n",
    "\n",
    "#C) merge with business_id PK\n",
    "BusinessParking_df = pd.merge(business_df['business_id'], BusinessParking_df, left_index=True, right_index=True)\n",
    "\n",
    "BusinessParking_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2fca52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#D) create and fill SQLite3 table (including FK index)\n",
    "c.execute('DROP TABLE IF EXISTS attributes_BusinessParking')\n",
    "conn.commit()\n",
    "\n",
    "c.execute(\"\"\"CREATE TABLE attributes_BusinessParking(\n",
    "                business_id text\n",
    "                ,garage integer\n",
    "                ,street integer\n",
    "                ,validated integer\n",
    "                ,lot integer\n",
    "                ,valet integer\n",
    "                ,CONSTRAINT fk_business_id  \n",
    "                FOREIGN KEY (business_id)  \n",
    "                REFERENCES business_main(business_id))\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "c.execute('CREATE INDEX IDX_attributes_BusinessParking on attributes_BusinessParking(business_id)')\n",
    "conn.commit()\n",
    "\n",
    "BusinessParking_df.to_sql('attributes_BusinessParking', conn, if_exists='append', index = False)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e27feb3",
   "metadata": {},
   "source": [
    "#### 3) attributes.Ambience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3ff3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A) the clean-up (including quotes, booleans and nan values)\n",
    "business_df['attributes.Ambience'] = business_df['attributes.Ambience'].replace(\"'\",'\"', regex=True)\n",
    "business_df['attributes.Ambience'] = business_df['attributes.Ambience'].replace('True','true', regex=True)\n",
    "business_df['attributes.Ambience'] = business_df['attributes.Ambience'].replace('False','false', regex=True)\n",
    "business_df['attributes.Ambience'] = business_df['attributes.Ambience'].replace('None','null', regex=True)\n",
    "\n",
    "#B) the normalization where we only apply JSON loads for x==x (NaN receives empty dict)\n",
    "Ambience_df = pd.json_normalize(business_df['attributes.Ambience'].apply(lambda x: json.loads(x) if(x == x) else {}))\n",
    "\n",
    "#C) merge with business_id PK\n",
    "Ambience_df = pd.merge(business_df['business_id'], Ambience_df, left_index=True, right_index=True)\n",
    "\n",
    "Ambience_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163b14ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#D) create and fill SQLite3 table (including FK index)\n",
    "c.execute('DROP TABLE IF EXISTS attributes_Ambience')\n",
    "conn.commit()\n",
    "\n",
    "c.execute(\"\"\"CREATE TABLE attributes_Ambience(\n",
    "                business_id text\n",
    "                ,touristy integer\n",
    "                ,hipster integer\n",
    "                ,romantic integer\n",
    "                ,divey integer\n",
    "                ,intimate integer\n",
    "                ,trendy integer\n",
    "                ,upscale integer\n",
    "                ,classy integer\n",
    "                ,casual integer\n",
    "                ,CONSTRAINT fk_business_id  \n",
    "                FOREIGN KEY (business_id)  \n",
    "                REFERENCES business_main(business_id))\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "c.execute('CREATE INDEX IDX_attributes_Ambience on attributes_Ambience(business_id)')\n",
    "conn.commit()\n",
    "\n",
    "Ambience_df.to_sql('attributes_Ambience', conn, if_exists='append', index = False)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98d36740",
   "metadata": {},
   "source": [
    "#### 4) attributes.GoodForMeal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb81bde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A) the clean-up (including quotes, booleans and nan values)\n",
    "business_df['attributes.GoodForMeal'] = business_df['attributes.GoodForMeal'].replace(\"'\",'\"', regex=True)\n",
    "business_df['attributes.GoodForMeal'] = business_df['attributes.GoodForMeal'].replace('True','true', regex=True)\n",
    "business_df['attributes.GoodForMeal'] = business_df['attributes.GoodForMeal'].replace('False','false', regex=True)\n",
    "business_df['attributes.GoodForMeal'] = business_df['attributes.GoodForMeal'].replace('None','null', regex=True)\n",
    "\n",
    "#B) the normalization where we only apply JSON loads for x==x (NaN receives empty dict)\n",
    "GoodForMeal_df = pd.json_normalize(business_df['attributes.GoodForMeal'].apply(lambda x: json.loads(x) if(x == x) else {}))\n",
    "\n",
    "#C) merge with business_id PK\n",
    "GoodForMeal_df = pd.merge(business_df['business_id'], GoodForMeal_df, left_index=True, right_index=True)\n",
    "\n",
    "GoodForMeal_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab9c5d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#D) create and fill SQLite3 table (including FK index)\n",
    "c.execute('DROP TABLE IF EXISTS attributes_GoodForMeal')\n",
    "conn.commit()\n",
    "\n",
    "c.execute(\"\"\"CREATE TABLE attributes_GoodForMeal(\n",
    "                business_id text\n",
    "                ,dessert integer\n",
    "                ,latenight integer\n",
    "                ,lunch integer\n",
    "                ,dinner integer\n",
    "                ,brunch integer\n",
    "                ,breakfast integer\n",
    "                ,CONSTRAINT fk_business_id  \n",
    "                FOREIGN KEY (business_id)  \n",
    "                REFERENCES business_main(business_id))\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "c.execute('CREATE INDEX IDX_attributes_GoodForMeal on attributes_GoodForMeal(business_id)')\n",
    "conn.commit()\n",
    "\n",
    "GoodForMeal_df.to_sql('attributes_GoodForMeal', conn, if_exists='append', index = False)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e5a107",
   "metadata": {},
   "source": [
    "#### 5) attributes.BestNights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6258fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A) the clean-up (including quotes, booleans and nan values)\n",
    "business_df['attributes.BestNights'] = business_df['attributes.BestNights'].replace(\"'\",'\"', regex=True)\n",
    "business_df['attributes.BestNights'] = business_df['attributes.BestNights'].replace('True','true', regex=True)\n",
    "business_df['attributes.BestNights'] = business_df['attributes.BestNights'].replace('False','false', regex=True)\n",
    "business_df['attributes.BestNights'] = business_df['attributes.BestNights'].replace('None','null', regex=True)\n",
    "\n",
    "#B) the normalization where we only apply JSON loads for x==x (NaN receives empty dict)\n",
    "BestNights_df = pd.json_normalize(business_df['attributes.BestNights'].apply(lambda x: json.loads(x) if(x == x) else {}))\n",
    "\n",
    "#C) merge with business_id PK\n",
    "BestNights_df = pd.merge(business_df['business_id'], BestNights_df, left_index=True, right_index=True)\n",
    "\n",
    "BestNights_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6cc593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#D) create and fill SQLite3 table (including PK index)\n",
    "c.execute('DROP TABLE IF EXISTS attributes_BestNights')\n",
    "conn.commit()\n",
    "\n",
    "c.execute(\"\"\"CREATE TABLE attributes_BestNights(\n",
    "                business_id text PRIMARY KEY\n",
    "                ,monday integer\n",
    "                ,tuesday integer\n",
    "                ,friday integer\n",
    "                ,wednesday integer\n",
    "                ,thursday integer\n",
    "                ,sunday integer\n",
    "                ,saturday integer\n",
    "                ,CONSTRAINT fk_business_id  \n",
    "                FOREIGN KEY (business_id)  \n",
    "                REFERENCES business_main(business_id))\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "c.execute('CREATE INDEX IDX_attributes_BestNights on attributes_BestNights(business_id)')\n",
    "conn.commit()\n",
    "\n",
    "BestNights_df.to_sql('attributes_BestNights', conn, if_exists='append', index = False)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee6625a",
   "metadata": {},
   "source": [
    "#### 6) attributes.Music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1308eb0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#A) the clean-up (including quotes, booleans and nan values)\n",
    "business_df['attributes.Music'] = business_df['attributes.Music'].replace(\"'\",'\"', regex=True)\n",
    "business_df['attributes.Music'] = business_df['attributes.Music'].replace('True','true', regex=True)\n",
    "business_df['attributes.Music'] = business_df['attributes.Music'].replace('False','false', regex=True)\n",
    "business_df['attributes.Music'] = business_df['attributes.Music'].replace('None','null', regex=True)\n",
    "\n",
    "#B) the normalization where we only apply JSON loads for x==x (NaN receives empty dict)\n",
    "Music_df = pd.json_normalize(business_df['attributes.Music'].apply(lambda x: json.loads(x) if(x == x) else {}))\n",
    "\n",
    "#C) merge with business_id PK\n",
    "Music_df = pd.merge(business_df['business_id'], Music_df, left_index=True, right_index=True)\n",
    "\n",
    "Music_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d93c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#D) create and fill SQLite3 table (including PK index)\n",
    "c.execute('DROP TABLE IF EXISTS attributes_Music')\n",
    "conn.commit()\n",
    "\n",
    "c.execute(\"\"\"CREATE TABLE attributes_Music(\n",
    "                business_id text PRIMARY KEY\n",
    "                ,dj integer\n",
    "                ,background_music integer\n",
    "                ,no_music integer\n",
    "                ,jukebox integer\n",
    "                ,live integer\n",
    "                ,video integer\n",
    "                ,karaoke integer\n",
    "                ,CONSTRAINT fk_business_id  \n",
    "                FOREIGN KEY (business_id)  \n",
    "                REFERENCES business_main(business_id))\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "c.execute('CREATE INDEX IDX_attributes_Music on attributes_Music(business_id)')\n",
    "conn.commit()\n",
    "\n",
    "Music_df.to_sql('attributes_Music', conn, if_exists='append', index = False)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ee0622",
   "metadata": {},
   "source": [
    "### II) USER DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3c60156",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can use pd.read_json as there are no nested objects\n",
    "user_df = pd.read_json(user_json, lines=True)\n",
    "\n",
    "user_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63df694f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#) create and fill SQLite3 table (including PK index)\n",
    "c.execute('DROP TABLE IF EXISTS user')\n",
    "conn.commit()\n",
    "\n",
    "c.execute(\"\"\"CREATE TABLE user(\n",
    "                user_id text PRIMARY KEY\n",
    "                ,name text\n",
    "                ,review_count integer\n",
    "                ,yelping_since text\n",
    "                ,useful integer\n",
    "                ,funny integer\n",
    "                ,cool integer\n",
    "                ,elite text\n",
    "                ,friends integer\n",
    "                ,fans integer\n",
    "                ,average_stars real\n",
    "                ,compliment_hot integer\n",
    "                ,compliment_more integer\n",
    "                ,compliment_profile integer\n",
    "                ,compliment_cute integer\n",
    "                ,compliment_list integer\n",
    "                ,compliment_note integer\n",
    "                ,compliment_plain integer\n",
    "                ,compliment_cool integer\n",
    "                ,compliment_funny integer\n",
    "                ,compliment_writer integer\n",
    "                ,compliment_photos integer)\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "user_df.to_sql('user', conn, if_exists='append', index = False)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af65bf7c",
   "metadata": {},
   "source": [
    "### III) CHECK-IN DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ef1791",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can use pd.read_json as there are no nested objects\n",
    "checkin_df = pd.read_json(checkin_json, lines=True)\n",
    "\n",
    "checkin_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab151ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#) create and fill SQLite3 table (including PK index)\n",
    "c.execute('DROP TABLE IF EXISTS checkin')\n",
    "conn.commit()\n",
    "\n",
    "c.execute(\"\"\"CREATE TABLE checkin(\n",
    "                business_id text\n",
    "                ,date text\n",
    "                ,CONSTRAINT fk_business_id  \n",
    "                FOREIGN KEY (business_id)  \n",
    "                REFERENCES business_main(business_id))\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "c.execute('CREATE INDEX IDX_checkin on checkin(business_id)')\n",
    "conn.commit()\n",
    "\n",
    "checkin_df.to_sql('checkin', conn, if_exists='append', index = False)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d6e325",
   "metadata": {},
   "source": [
    "### IV) REVIEW DATA\n",
    ">dataset contains no nested objects, however split is required as file is to large for local memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a55b206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#) create SQLite3 table (including PK index & Foreign keys)\n",
    "c.execute('DROP TABLE IF EXISTS review')\n",
    "conn.commit()\n",
    "\n",
    "c.execute(\"\"\"CREATE TABLE review(\n",
    "                review_id text PRIMARY KEY\n",
    "                ,user_id text\n",
    "                ,business_id text\n",
    "                ,stars real\n",
    "                ,useful integer\n",
    "                ,funny integer\n",
    "                ,cool integer\n",
    "                ,text text\n",
    "                ,date text\n",
    "                ,CONSTRAINT fk_user_id  \n",
    "                FOREIGN KEY (user_id)  \n",
    "                REFERENCES user(user_id)\n",
    "                ,CONSTRAINT fk_business_id  \n",
    "                FOREIGN KEY (business_id)  \n",
    "                REFERENCES business_main(business_id))\"\"\")\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a87ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#open file as a whole\n",
    "f = open(review_json, 'r', encoding='utf-8').readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d2f609",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cache_A = []\n",
    "for line in itertools.islice(f,0,2000000):\n",
    "  line = line.strip()\n",
    "  if not line: continue\n",
    "  list_cache_A.append(json.loads(line))\n",
    "review_df_A = pd.json_normalize(list_cache_A, max_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7270ad3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_A.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14928c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_A.to_sql('review', conn, if_exists='append', index = False)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c25614a",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cache_B = []\n",
    "for line in itertools.islice(f,2000000,4000000):\n",
    "  line = line.strip()\n",
    "  if not line: continue\n",
    "  list_cache_B.append(json.loads(line))\n",
    "review_df_B = pd.json_normalize(list_cache_B, max_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beb4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_B.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0a193a",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_B.to_sql('review', conn, if_exists='append', index = False)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69aa0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cache_C = []\n",
    "for line in itertools.islice(f,4000000,6000000):\n",
    "  line = line.strip()\n",
    "  if not line: continue\n",
    "  list_cache_C.append(json.loads(line))\n",
    "review_df_C = pd.json_normalize(list_cache_C, max_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce9382e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "review_df_C.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af23dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_C.to_sql('review', conn, if_exists='append', index = False)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d87e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cache_D = []\n",
    "for line in itertools.islice(f,6000000,9999999):\n",
    "  line = line.strip()\n",
    "  if not line: continue\n",
    "  list_cache_D.append(json.loads(line))\n",
    "review_df_D = pd.json_normalize(list_cache_D, max_level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c7b659",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_D.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765e3a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_df_D.to_sql('review', conn, if_exists='append', index = False)\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b17457c",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.execute('CREATE INDEX IDX_review_business_id on review(business_id)')\n",
    "c.execute('CREATE INDEX IDX_review_user_business on review(user_id)')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bff09fa",
   "metadata": {},
   "source": [
    "### V) TIP DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a822b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we can use pd.read_json as there are no nested objects\n",
    "tip_df = pd.read_json(tip_json, lines=True)\n",
    "\n",
    "tip_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb7d4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#) create and fill SQLite3 table\n",
    "c.execute('DROP TABLE IF EXISTS tip')\n",
    "conn.commit()\n",
    "\n",
    "c.execute(\"\"\"CREATE TABLE tip(\n",
    "                user_id text\n",
    "                ,business_id text\n",
    "                ,text text\n",
    "                ,date text\n",
    "                ,compliment_count integer\n",
    "                ,CONSTRAINT fk_user_id  \n",
    "                FOREIGN KEY (user_id)  \n",
    "                REFERENCES user(user_id)\n",
    "                ,CONSTRAINT fk_business_id  \n",
    "                FOREIGN KEY (business_id)  \n",
    "                REFERENCES business_main(business_id))\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "tip_df.to_sql('tip', conn, if_exists='append', index = False)\n",
    "conn.commit()\n",
    "\n",
    "c.execute('CREATE INDEX IDX_tip_user_id on tip(user_id)')\n",
    "c.execute('CREATE INDEX IDX_tip_business_id on tip(business_id)')\n",
    "c.execute('CREATE INDEX IDX_tip_user_business on tip(user_id,business_id)')\n",
    "conn.commit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
